# üìà Time Series Forecasting of Bike Demand with Machine Learning
This project presents a complete time series forecasting pipeline for a bike-sharing demand dataset, developed in Python. The work focuses on modeling, feature engineering, and performance evaluation using multiple regression algorithms.

The goal was to identify the model that best captures temporal dependencies and generalizes effectively to unseen data. After extensive experimentation, the HistGradientBoostingRegressor (HGB) was selected as the final model.

---

## üß© Project Overview

This project implements a **machine learning-based approach** for forecasting a time-dependent variable.  
The main objectives were:

- To perform robust **feature engineering** for time series data.
- To encode cyclical features (e.g., hours, days, months) effectively.
- To generate **lagged** and **rolling features** to capture temporal dependencies.
- To evaluate several **regression models** using **cross-validation with `TimeSeriesSplit`**.
- To identify the model with the best generalization performance.
- To train and validate the final model (HGB) on real data.

---

## ‚öôÔ∏è Workflow Summary

### 1. Data Preprocessing

Before modeling, data cleaning and preparation steps were applied to ensure reliability and consistency:

- Calculate the coefficiente of variation of some features, to understand their variability.
- Encoding of Cyclical Features from temporal columns, such as hour, day of the week, and month, to help the model capture temporal patterns.
- Consolidated the rare heavy_rain category (only 3 instances) into the broader rain category to reduce noise and prevent model overfitting.
- Normalization of numeric values where applicable.

---

### 2. Feature Engineering

To enrich the dataset and improve predictive power, several feature transformations were performed.

#### üîÅ Lagged Features

Lagged features were created to allow the model to capture temporal dependencies by incorporating past values of the target variable. The specific lags were selected based on insights from ACF and PACF plots. The following lagged features were generated:

- 25-hour lag for "temp", "feel_temp", "humidity", and "windspeed".
- 143-hour lag for the same set of features.

#### üìâ Rolling Features

Rolling window statistics were applied to create smoothed representations of the series and capture recent variability. The window sizes were determined using the same analytical method as the lags. The generated features include:

- 48-hour rolling mean and standard deviation for "temp", "feel_temp", "humidity", and "windspeed".
- 168-hour rolling mean and standard deviation for the same columns.

These features are designed to capture medium-term trends and volatility in the data.

### 3. Data Splitting and Cross-Validation

Instead of a random split, TimeSeriesSplit was used to maintain the chronological order of the data and ensure realistic model evaluation.

This technique prevents data leakage and mimics real-world forecasting scenarios where future data is never available during training.

### 4. Model Evaluation

Multiple algorithms and metrics were tested to assess performance. Each model was evaluated using cross-validation, and the following metrics were calculated for both training and testing sets:

- **NMAE Negative Mean Absolute Error**

- RIDGE: -0.093172 (0.008721)
- LASSO: -0.092691 (0.008623)
- ENET: -0.092693 (0.008624)
- NN (MLP): -0.063116 (0.006311)
- RF: -0.076823 (0.007322)
- XGBoost: -0.062710 (0.004100)
- LGBM: -0.058437 (0.004295)
- HGB: -0.058410 (0.004338)

- **R¬≤ Coefficient of Determination**

- RIDGE: 0.601190 (0.085044)
- LASSO: 0.603184 (0.087896)
- ENET: 0.603186 (0.087893)
- NN: 0.808309 (0.043714)
- RF: 0.733283 (0.056201)
- XG: 0.814273 (0.048524)
- LGBM: 0.823377 (0.058416)
- HGB: 0.823732 (0.048395)

### 5. Final Model: HistGradientBoostingRegressor (HGB)

The HGB model was trained on the full training dataset and evaluated on the test set.
It showed excellent performance with low errors and strong predictive power.

### üìä Model Performance Analysis

#### High R¬≤ (Train: 0.9886, Test: 0.8317):
- The model captures most of the variance while maintaining good generalization.

#### Low MAE and RMSE:
- The predictions remain close to real values both in training and testing.

#### Minimal Bias:
- Slight underestimation observed in the test set, which can be addressed with calibration or bias correction.

#### No Overfitting:
- The small gap between training and testing performance suggests that the model learned general patterns rather than memorizing data.


### üîç Residuals Analysis

Residuals (prediction errors) are centered around zero and show no visible trend or autocorrelation.
This indicates that the model made balanced predictions and did not systematically overestimate or underestimate the target variable.


### üß† Why HistGradientBoostingRegressor?

The HGB model was chosen because it combines:

- Strong predictive performance on structured tabular data.

- Ability to model nonlinear relationships.

- Smooth regularization mechanisms, reducing overfitting.

- It achieved the best trade-off between accuracy, interpretability, and computational cost.


### üßë‚Äçüíª Author

##### **Bernardo Costa**

- Data Analyst & Data Scientist in graduation
- üìç Brazil
- üíº LinkedIn -> https://www.linkedin.com/in/bernardobadc/
- üìä GitHub -> https://github.com/bernardobadc

-------------------------------------------------------------------------------------------------------------------------------------------------

# PORTUGUESE

# üìà Previs√£o de S√©ries Temporais da Demanda de Bicicletas com Machine Learning

Este projeto apresenta um pipeline completo de previs√£o de s√©ries temporais para um conjunto de dados de demanda de bicicletas compartilhadas, desenvolvido em Python. O trabalho foca na modelagem, engenharia de features e avalia√ß√£o de desempenho usando m√∫ltiplos algoritmos de regress√£o.

O objetivo foi identificar o modelo que melhor captura depend√™ncias temporais e generaliza efetivamente para dados n√£o vistos. Ap√≥s extensiva experimenta√ß√£o, o **HistGradientBoostingRegressor (HGB)** foi selecionado como modelo final.

---

## üß© Vis√£o Geral do Projeto

Este projeto implementa uma **abordagem baseada em machine learning** para prever uma vari√°vel dependente do tempo.  
Os principais objetivos foram:

- Realizar **engenharia de features** robusta para dados de s√©ries temporais.
- Codificar features c√≠clicas (como hora, dia, m√™s) de forma efetiva.
- Gerar **features defasadas (lagged)** e **features de rolling** para capturar depend√™ncias temporais.
- Avaliar v√°rios **modelos de regress√£o** usando **valida√ß√£o cruzada com `TimeSeriesSplit`**.
- Identificar o modelo com melhor desempenho de generaliza√ß√£o.
- Treinar e validar o modelo final (HGB) em dados reais.

---

## ‚öôÔ∏è Resumo do Fluxo de Trabalho

### 1. Pr√©-processamento de Dados

Antes da modelagem, etapas de limpeza e prepara√ß√£o de dados foram aplicadas para garantir confiabilidade e consist√™ncia:

- C√°lculo do coeficiente de varia√ß√£o de algumas features para entender sua variabilidade.
- Codifica√ß√£o de Features C√≠clicas a partir de colunas temporais, como hora, dia da semana e m√™s, para ajudar o modelo a capturar padr√µes temporais.
- Consolida√ß√£o da categoria rara `heavy_rain` (apenas 3 inst√¢ncias) na categoria mais ampla `rain` para reduzir ru√≠do e prevenir overfitting do modelo.
- Normaliza√ß√£o de valores num√©ricos quando aplic√°vel.

---

### 2. Engenharia de Features

Para enriquecer o conjunto de dados e melhorar o poder preditivo, v√°rias transforma√ß√µes de features foram realizadas.

#### üîÅ Features Defasadas (Lagged Features)

Features defasadas foram criadas para permitir que o modelo capture depend√™ncias temporais incorporando valores passados da vari√°vel target. Os lags espec√≠ficos foram selecionados com base em insights dos gr√°ficos ACF e PACF. As seguintes features defasadas foram geradas:

- Lag de 25 horas para "temp", "feel_temp", "humidity" e "windspeed".
- Lag de 143 horas para o mesmo conjunto de features.

#### üìâ Features de Rolling

Estat√≠sticas de janela m√≥vel (rolling) foram aplicadas para criar representa√ß√µes suavizadas da s√©rie e capturar variabilidade recente. Os tamanhos das janelas foram determinados usando o mesmo m√©todo anal√≠tico dos lags. As features geradas incluem:

- M√©dia m√≥vel e desvio padr√£o de 48 horas para "temp", "feel_temp", "humidity" e "windspeed".
- M√©dia m√≥vel e desvio padr√£o de 168 horas para as mesmas colunas.

Essas features foram projetadas para capturar tend√™ncias de m√©dio prazo e volatilidade nos dados.

### 3. Divis√£o de Dados e Valida√ß√£o Cruzada

Em vez de uma divis√£o aleat√≥ria, o `TimeSeriesSplit` foi usado para manter a ordem cronol√≥gica dos dados e garantir uma avalia√ß√£o realista do modelo.

Esta t√©cnica previne vazamento de dados e simula cen√°rios reais de previs√£o onde dados futuros nunca est√£o dispon√≠veis durante o treinamento.

### 4. Avalia√ß√£o dos Modelos

M√∫ltiplos algoritmos e m√©tricas foram testados para avaliar o desempenho. Cada modelo foi avaliado usando valida√ß√£o cruzada, e as seguintes m√©tricas foram calculadas para conjuntos de treino e teste:

- **NMAE (Negative Mean Absolute Error)**

- RIDGE: -0.093172 (0.008721)
- LASSO: -0.092691 (0.008623)
- ENET: -0.092693 (0.008624)
- NN (MLP): -0.063116 (0.006311)
- RF: -0.076823 (0.007322)
- XGBoost: -0.062710 (0.004100)
- LGBM: -0.058437 (0.004295)
- HGB: -0.058410 (0.004338)

- **R¬≤ (Coeficiente de Determina√ß√£o)**

- RIDGE: 0.601190 (0.085044)
- LASSO: 0.603184 (0.087896)
- ENET: 0.603186 (0.087893)
- NN: 0.808309 (0.043714)
- RF: 0.733283 (0.056201)
- XG: 0.814273 (0.048524)
- LGBM: 0.823377 (0.058416)
- HGB: 0.823732 (0.048395)

### 5. Modelo Final: HistGradientBoostingRegressor (HGB)

O modelo HGB foi treinado em todo o conjunto de dados de treinamento e avaliado no conjunto de teste. Ele mostrou excelente desempenho com baixos erros e forte poder preditivo.

### üìä An√°lise de Desempenho do Modelo

#### Alto R¬≤ (Treino: 0.9886, Teste: 0.8317):
- O modelo captura a maior parte da vari√¢ncia enquanto mant√©m boa generaliza√ß√£o.

#### Baixo MAE e RMSE:
- As previs√µes permanecem pr√≥ximas dos valores reais tanto no treinamento quanto no teste.

#### Vi√©s M√≠nimo:
- Subestima√ß√£o leve observada no conjunto de teste, que pode ser abordada com calibra√ß√£o ou corre√ß√£o de vi√©s.

#### Sem Overfitting:
- A pequena diferen√ßa entre o desempenho de treino e teste sugere que o modelo aprendeu padr√µes gerais em vez de memorizar os dados.

### üîç An√°lise de Res√≠duos

Os res√≠duos (erros de previs√£o) est√£o centrados em torno de zero e n√£o mostram tend√™ncia vis√≠vel ou autocorrela√ß√£o. Isso indica que o modelo fez previs√µes balanceadas e n√£o superestimou ou subestimou sistematicamente a vari√°vel target.

### üß† Por que HistGradientBoostingRegressor?

O modelo HGB foi escolhido porque combina:

- Forte desempenho preditivo em dados tabulares estruturados.
- Capacidade de modelar rela√ß√µes n√£o lineares.
- Mecanismos de regulariza√ß√£o suaves, reduzindo overfitting.
- Conseguiu o melhor equil√≠brio entre acur√°cia, interpretabilidade e custo computacional.

### üßë‚Äçüíª Autor

##### **Bernardo Costa**

- Data Analyst & Data Scientist em forma√ß√£o
- üìç Brasil
- üíº LinkedIn -> https://www.linkedin.com/in/bernardobadc/
- üìä GitHub -> https://github.com/bernardobadc